name: PyTest PySpark constructor

on:
  pull_request:
    types: [opened, labeled, synchronize]  # Triggers on PR creation, updates, and label changes

env:
  PY_COLORS: 1

jobs:

  pytest-pyspark-constructor:
    if: ${{ contains(github.event.pull_request.labels.*.name, 'pyspark') || contains(github.event.pull_request.labels.*.name, 'release') }}
    strategy:
      matrix:
        python-version: ["3.10", "3.11"]
        os: [ubuntu-latest]
    runs-on: ${{ matrix.os }}
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-python@v5
        with:
          python-version: ${{ matrix.python-version }}
      - name: Install uv
        uses: astral-sh/setup-uv@v5
        with:
          enable-cache: "true"
          cache-suffix: ${{ matrix.python-version }}
          cache-dependency-glob: "pyproject.toml"
      - name: install-reqs
        run: uv pip install -e . --group core-tests --group extra --system
      - name: install pyspark
        run: echo "setuptools<78" | uv pip install -b - -e ".[pyspark]" --system
      - name: show-deps
        run: uv pip freeze
      - name: Run pytest
        run: pytest tests --cov=narwhals/_spark_like --cov-fail-under=95 --runslow --constructors pyspark


  pytest-pyspark-connect-constructor:
    if: ${{ contains(github.event.pull_request.labels.*.name, 'pyspark-connect') || contains(github.event.pull_request.labels.*.name, 'release') }}
    strategy:
      matrix:
        python-version: ["3.10", "3.11"]
        os: [ubuntu-latest]
    env:
      SPARK_VERSION: 3.5.5
      SPARK_PORT: 15002
      SPARK_CONNECT: true
    runs-on: ${{ matrix.os }}
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-python@v5
        with:
          python-version: ${{ matrix.python-version }}

      - name: Install uv
        uses: astral-sh/setup-uv@v5
        with:
          enable-cache: "true"
          cache-suffix: ${{ matrix.python-version }}
          cache-dependency-glob: "pyproject.toml"

      - name: Set up JDK
        uses: actions/setup-java@v4
        with:
          java-version: '11'
          distribution: 'temurin'

      - name: install-reqs
        run: uv pip install -e . --group core-tests --group extra --system
      - name: install pyspark
        run: echo "setuptools<78" | uv pip install -e . "pyspark[connect]==${SPARK_VERSION}" --system
      - name: show-deps
        run: uv pip freeze

      - name: Download Spark
        run: |
          wget https://archive.apache.org/dist/spark/spark-${SPARK_VERSION}/spark-${SPARK_VERSION}-bin-hadoop3.tgz
          tar -xzf spark-${SPARK_VERSION}-bin-hadoop3.tgz
          echo "SPARK_HOME=$PWD/spark-${SPARK_VERSION}-bin-hadoop3" >> $GITHUB_ENV
          echo "$PWD/spark-${SPARK_VERSION}-bin-hadoop3/bin" >> $GITHUB_PATH

      - name: Start Spark Connect server
        run: |
          ./spark-${SPARK_VERSION}-bin-hadoop3/sbin/start-connect-server.sh --packages org.apache.spark:spark-connect_2.12:${SPARK_VERSION}
          sleep 5
          echo "Spark Connect server started"

      - name: Run pytest
        run: pytest tests --cov=narwhals/_spark_like --cov-fail-under=95 --runslow --constructors "pyspark[connect]"

      - name: Stop Spark Connect server
        if: always()
        run: |
          ./spark-${SPARK_VERSION}-bin-hadoop3/sbin/stop-connect-server.sh
